---
layout: post
title: Multi-view Noise2Void 
categories: Computer Vision
tags:
mathjax: true
comments: true
---
 
(From [Pathak et al, 2016](https://people.eecs.berkeley.edu/~pathak/papers/cvpr16.pdf))
> "Like  autoencoders,  context  encoders  are  trained  in  a completely unsupervised manner.  Our results demonstrate that in order to succeed at this task, a model needs to both understand the content of an image,  as well as produce aplausible hypothesis for the missing parts.  This task, however, is inherently multi-modal as there are multiple ways to fill the missing region while also maintaining coherence with the given context. We decouple this burden in our loss function by jointly training our context encoders to minimize both a reconstruction loss and an adversarial loss. The reconstruction (L2) loss captures the overall structure of the missing region in relation to the context, while the the adversarial loss has the effect of picking a particular mode from the distribution."

Pathak et al employ an unsupervised strategy quite similar to Noise2Void but for the task of Inpainting. Their loss comprises of two components: an MSE loss (similar to Noise2Void) and an additional adversarial loss, with the former weighted by 0.999 and the latter weighted by 0.001. I wonder whether such a loss could be extended for use to denoise patches in Noise2Void?

<p float="center"><figure>
<img src="../images/2019-08-12/01_imageOne.jpg" />
<figcaption>
[Figure One : Semantic Inpainting results on held-out images by Context Encoder]</figcaption></figure>
</p>



We thought that it would be a cool idea to use Noise2Void-type unsupervised learning in order to reconstruct images, obtained through the two cameras of light-sheet microscopy. 

## Experiment One

Applied equal weighting on the L2 loss on the predicted intensity value on the blind-spot pixel and the corresponding pixels in the two patches arising from the two cameras.

## Experiment Two

Have L2 loss between the predicted intensity value on the predicted intensity value of the blind spot pixel and the original pixel in the noisy image from which it was extracted, and adversarial loss on the corresponding pixel arising from the second camera.


